{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN/D7vufTYXmCG5nVODr/W+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gittymarina/merogit/blob/master/US_BANKRUPTCY_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyJbyvg9LP4s"
      },
      "outputs": [],
      "source": [
        "#IMPORTING OUR LIABARIES\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "from sklearn.metrics import recall_score,precision_score,f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOADING OUR DATASET\n",
        "df=pd.read_csv(\"american_bankruptcy.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "zquOdjFSQ4Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNDERSTANDING THE LENGTH OF DATASET"
      ],
      "metadata": {
        "id": "eNhqGxvBBf3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "Rx4k1F6bDhKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHANGING OUR COLUMN NAMES INORDER TO EASILY UNDERSTAND OUR VARIABLES"
      ],
      "metadata": {
        "id": "JVe2Yh3hcv94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_names=['company_name','status_label','year','current_assets','cost of goods sold','depreciation and amortization','EBITDA','inventory','net income',\n",
        "                                                'total receivables','market value','net sales','total assets','total long term debt','EBIT','gross profit','total current liabilities',\n",
        "                                                'retained earnings','total revenue','total liabilities','total operating expenses']\n"
      ],
      "metadata": {
        "id": "Egi-rOALMLWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=columns_names\n",
        "df"
      ],
      "metadata": {
        "id": "eUe7M_otSW_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INFORMATION ABOUT OUR DATASET"
      ],
      "metadata": {
        "id": "JGDigcLRc9fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "dJEK1wQqSYNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DESCRIPTION OF OUR DATASET"
      ],
      "metadata": {
        "id": "1kDd8g2RdCsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "dingW82tSbq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING OUT THE NULL VALUES IN THE DATASET"
      ],
      "metadata": {
        "id": "Rf7lE64ndHca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "pWKHXXaLSdvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DROPPING THE DUPLICATES IN THE DATASET"
      ],
      "metadata": {
        "id": "veIYHoejdNTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates()"
      ],
      "metadata": {
        "id": "uqyZJip1Skra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNDERSTANDING THE DATASET USING BARPLOTS"
      ],
      "metadata": {
        "id": "OhkPQpTAdT8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "categorical_cols=['current_assets','cost of goods sold','depreciation and amortization','EBITDA','inventory','net income',\n",
        "                                                'total receivables','market value','net sales','total assets']\n",
        "\n",
        "plt.figure(figsize=(20,40))\n",
        "for i,col in enumerate(categorical_cols,1):\n",
        "  plt.subplot(11,1,i)\n",
        "  sns.barplot(x=col,y='status_label',data =df)\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('status_label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "r3-_2kqhSrga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INFERENCE: INCREASE IN TOTAL ASSETS AND DEPRECIATION AND AMORTIZATION HAS LEFT THE COMPANY TO BANKRUPT\n",
        "\n",
        "NEGATIVE NET INCOME:\n",
        "   our company is having other positive sales but its expenses & other costs are being exceeded the amt taken in as revenue"
      ],
      "metadata": {
        "id": "2oPcFE63dfrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "categorical_cols=['total long term debt','EBIT','gross profit','total current liabilities',\n",
        "                  'retained earnings','total revenue','total liabilities','total operating expenses']\n",
        "\n",
        "plt.figure(figsize=(20,40))\n",
        "for i,col in enumerate(categorical_cols,1):\n",
        "  plt.subplot(11,1,i)\n",
        "  sns.barplot(x=col,y='status_label',data =df)\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('status_label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hv601cXbSu9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INFERENCE:\n",
        "\n",
        "increase in total liabilities and total operating expenses and total revenue\n",
        "has left the company bankrupt\n",
        "\n",
        "NEGATIVE RETAINED EARNINGS:\n",
        "our retained earnings goes to minus because of cumulative net loss (i.e the excess of net loss previously allocated to members over the net income previously allocated to the members)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T6LIviyeekif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING CORRELATION BETWEEN VARIABLES THROUGH HEATMAP"
      ],
      "metadata": {
        "id": "XhH2QAEkd2jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.heatmap(df.corr(),annot=True,cmap=\"viridis\")"
      ],
      "metadata": {
        "id": "4qWzRxmES20w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING CORRELATED VARIABLES AND THEIR  CORRELATED VALUES"
      ],
      "metadata": {
        "id": "4QBjIkHX0tZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "rNhUlsmGTsJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE ARE DROPPING THE VARIABLES WERE OUR VALUES ARE CORRELATED"
      ],
      "metadata": {
        "id": "fHjap4MD03KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"gross profit\",axis=1)"
      ],
      "metadata": {
        "id": "IfpSPFHvMUp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " \"Cost of goods sold\" and \"Net sales\" are strongly correlated, but not the same factor. However, \"Gross profit\" is actually equal net sales subtracted cost of goods sold, so this feature can be dropped to decrease multicollinearity."
      ],
      "metadata": {
        "id": "nTejLfby5Ffd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"total revenue\",axis=1)"
      ],
      "metadata": {
        "id": "KCPtgIQpTow9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Net sales\" and \"Total revenue\" are identical and therefore perfectly correlated. Dropping one to decrease multicollinearity."
      ],
      "metadata": {
        "id": "kiOUPDEj5e_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"total operating expenses\",axis=1)\n"
      ],
      "metadata": {
        "id": "NWWTmWewT2Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is also a near-perfect correlation between \"Cost of goods sold\" and  \"Total Operating Expenses\". It seems that 'cost of goods sold is a subset of all expenses covered in 'total operating expenses'.'total opearting expenses' will then be dropped to reduce multicollinearity."
      ],
      "metadata": {
        "id": "gsWWnYVo6upS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"EBIT\",axis=1)"
      ],
      "metadata": {
        "id": "fEvUetD0T6KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variables X4 \"EBITDA\" and X12 \"EBIT\" are very strongly correlated with their difference being captured in X3 \"Depreciation and amortization\", i.e. X3 = X4 - X12. Thus, X12 can be dropped to decrease multicollinearity."
      ],
      "metadata": {
        "id": "cXeTTAL37Z8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABEL ENCODING OUR VALUES WHERE OUR VARIABLE LIKE COMPANY NAME,STATUS LABEL ARE IN STRING"
      ],
      "metadata": {
        "id": "iGSr7mme1Ihv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label=preprocessing.LabelEncoder()\n",
        "df['status_label']=label.fit_transform(df['status_label'])\n"
      ],
      "metadata": {
        "id": "NmkdLOsIWVWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS OUR STATUS LABEL IS IN OBJECT TYPE SO WE DO LABEL ENCODING INORDER TO CONVERT TO FLOAT AS zeros'0'AND ones'1'"
      ],
      "metadata": {
        "id": "xcnnRrS27vI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FITTING OUR MODEL IN LOGISTICS REGRESSION"
      ],
      "metadata": {
        "id": "GqnQjwuG1uw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop('status_label',axis=1)\n",
        "y=df['status_label']\n",
        "x=pd.get_dummies(x,drop_first=True)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,random_state=50)\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "predictions=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_test,predictions)\n",
        "conf_matrix=confusion_matrix(y_test,predictions)\n",
        "class_report=classification_report(y_test,predictions)\n",
        "print('accuracy:',accuracy)\n",
        "print(\"confusion matrix:\\n\",conf_matrix)\n",
        "print('classification report:\\n',class_report)"
      ],
      "metadata": {
        "id": "VGNHpzrtW1Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FITTING OUR MODEL IN RANDOM FOREST"
      ],
      "metadata": {
        "id": "Qg1Cf5QD13Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ran=RandomForestClassifier()\n",
        "ran.fit(x_train,y_train)\n",
        "y_pred=ran.predict(x_test)\n",
        "accuracy1=accuracy_score(y_test,y_pred)\n",
        "classif_report=classification_report(y_test,y_pred)\n",
        "conf_mat=confusion_matrix(y_test,y_pred)\n",
        "print(\"accuracy score:\",accuracy1)\n",
        "print('classification report:',classif_report)\n",
        "print('confusion matrix:',conf_mat)"
      ],
      "metadata": {
        "id": "Y6YEMBu1M1X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FITTING OUR MODEL IN DECISION TREE"
      ],
      "metadata": {
        "id": "t1upAcxi2ATg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred1=clf.predict(x_test)\n",
        "accuracy=accuracy_score(y_test,y_pred1)\n",
        "classification_report=classification_report(y_test,y_pred1)\n",
        "confusion_mat=confusion_matrix(y_test,y_pred1)\n",
        "print(\"acuracy score:\",accuracy)\n",
        "print('classification report:',classification_report)\n",
        "print('confusion matrix:',confusion_mat)"
      ],
      "metadata": {
        "id": "SW-sV_KkOzn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE ARE TABULATING OUR PERFORMANCE MATRICES OF VARIOUS ALGORITHMS IN A TABLE FORM."
      ],
      "metadata": {
        "id": "2YHVNUXT2VBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores=['accuracy','precision','F1','Recall']\n",
        "name=['LOGISTIC REGRESSION','DESICION TREE','RANDOM FOREST']\n",
        "pred=[predictions,y_pred1,y_pred]\n",
        "Accuracy=[]\n",
        "precision=[]\n",
        "f1=[]\n",
        "recall=[]\n",
        "\n",
        "for j in pred:\n",
        "  Accuracy.append(accuracy_score(j,y_test))\n",
        "  precision.append(precision_score(j,y_test))\n",
        "  f1.append(f1_score(j,y_test))\n",
        "  recall.append(recall_score(j,y_test))\n",
        "eval_scores=pd.DataFrame(\n",
        "    {'MODELS':name,\n",
        "     'ACCURACY':Accuracy,\n",
        "     'PRECISION':precision,\n",
        "     'F1':f1,\n",
        "     'RECALL':recall}\n",
        ")\n",
        "eval_scores"
      ],
      "metadata": {
        "id": "3ZmKHR-HUPS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BAR PLOT**"
      ],
      "metadata": {
        "id": "VNgB3QkETeeN"
      }
    },
    {
      "source": [
        "\n",
        "eval_scores.groupby('MODELS').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_sr0me1F76sn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}